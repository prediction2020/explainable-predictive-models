# -----------------------------------------------------------------------------------
# SET PATH VARIABLES
# -----------------------------------------------------------------------------------


data path : data/1kplus_data_and_labels_outcome_pred.pkl
splits path : data/1kplus_training_test_sets.pkl

dataset name : &dataname 1kplus
main results folder : &mainsavepath modeling_results/
models folder path : !join [*mainsavepath, *dataname, /models]
parameters folder path : !join [*mainsavepath, *dataname, /parameters]
importance folder path : !join [*mainsavepath, *dataname, /feature_importance_values]
scores folder path : !join [*mainsavepath, *dataname, /performance_scores]
figures folder path : !join [*mainsavepath, *dataname, /figures]

# -----------------------------------------------------------------------------------
# SET IMPLEMENTATION VARIABLES
# -----------------------------------------------------------------------------------

# 1. Data properties ----------------------------------------------------------------

features: 
  AD_NIH : NIHSS
  AT_LY : thrombolysis treatment
  DG_SEX : sex
  RF_DM : diabetes
  RF_HC : hypercholesterol
  DG_AG : age 
  CH : cardiac history

# 2. Modeling Properties ------------------------------------------------------------

models to use :
  - GLM
  - Lasso
  - ElasticNet
  - Catboost
  - MLP

test size : 0.2

number of splits :  2

final performance measures :
  - AUC
  - accuracy
  - average_class_accuracy
  - f1

subsampling to use :
  - random

fixed hyperparameters:
  GLM :
    C : 100000000000000
    fit_intercept : no
    penalty : l1
    solver : saga
    tol : 0.001
    max_iter : 10000
    n_jobs : -1

  Lasso :
    fit_intercept : no
    penalty : l1
    solver : saga
    tol : 0.001
    max_iter : 10000
    n_jobs : -1

  ElasticNet :
    loss : log
    penalty : elasticnet
    fit_intercept : no
    tol : 0.001
    max_iter : 10000
    n_jobs : -1

  Catboost :
    od_type : Iter
    od_wait : 40

  MLP :
    monitor : val_loss
    mode : min
    epochs : 50
    iter_patience : 2
    min_delta : 0.005
    hidden_activation : relu
    out_activation : sigmoid
    loss_func : binary_crossentropy
    optimizer : adam
    weight_init : uniform

# 2.1. Grid Search Options ----------------------------------------------------------

use gridsearch : Yes

cross-validation folds : 10

cross-validation score : AUC

tuning hyperparameters :
  GLM : None

  Lasso :
    C : [0.1, 0.1207, 0.1456, 0.1758, 0.2121, 0.256, 0.3089, 0.3728, 0.4498, 
         0.5429, 0.6551, 0.7906, 0.9541, 1.1514, 1.3895, 1.6768, 2.0236, 
         2.4421, 2.9471, 3.5565, 4.2919, 5.1795, 6.2506, 7.5431, 9.103, 
         10.9854, 13.2571, 15.9986, 19.307, 23.2995, 28.1177, 33.9322, 
         40.9492, 49.4171, 59.6362, 71.9686, 86.8511, 104.8113, 126.4855, 
         152.6418, 184.207, 222.2996, 268.2696, 323.7458, 390.694, 471.4866, 
         568.9866, 686.6488, 828.6428, 1000.0]

  ElasticNet :
    l1_ratio : [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 
                0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]
    alpha : [0.00001, 0.00004, 0.00016, 0.0006, 0.0025, 0.01, 0.04, 0.16, 
             0.63, 2.5, 10.0]

  Catboost :
    l2_leaf_reg : [3.,10.,100.,500.]
    depth : [2.,4.]
    leaf_estimation_iterations : [1.,2.]
    bagging_temperature : [0.6,0.8,1.]
    learning_rate : [0.03,0.1,0.3]

  MLP :
    batch_size : [16,32]
    num_neurons : [5,10,15,20]
    learning_rate : [0.001, 0.01]
    dropout_rate : [0.1, 0.2]
    l1_ratio : [0.0001,0.001]

# 3. Saving options ------------------------------------------------------------------






